import json
import requests
import concurrent.futures
from urllib.parse import urlparse
import time
import argparse

def check_stream(url, original_url):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å—Ç—Ä–∏–º–∞ –ø–æ HTTPS URL
    """
    test_url = url
    try:
        # –ï—Å–ª–∏ URL –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http:, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ https:
        if url.startswith('http:'):
            test_url = url.replace('http:', 'https:', 1)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º URL, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å http:
        if test_url.startswith('http:'):
            return {
                'original_url': original_url,
                'tested_url': test_url,
                'status': 'skipped',
                'reason': 'HTTP protocol not supported'
            }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36',
            'Range': 'bytes=0-4096'
        }
        
        response = requests.get(
            test_url,
            headers=headers,
            timeout=15,
            stream=True
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–¥
        if response.status_code in [200, 206]:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –Ω–µ–±–æ–ª—å—à–æ–π –∫—É—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö
            data_chunk = next(response.iter_content(chunk_size=1024), None)
            if data_chunk and len(data_chunk) > 0:
                return {
                    'original_url': original_url,
                    'tested_url': test_url,
                    'status': 'good',
                    'http_status': response.status_code,
                    'content_type': response.headers.get('content-type', 'Unknown'),
                    'content_length': len(data_chunk)
                }
            else:
                return {
                    'original_url': original_url,
                    'tested_url': test_url,
                    'status': 'bad',
                    'reason': 'No data received',
                    'http_status': response.status_code
                }
        else:
            return {
                'original_url': original_url,
                'tested_url': test_url,
                'status': 'bad',
                'reason': f'HTTP status {response.status_code}',
                'http_status': response.status_code
            }
            
    except requests.exceptions.Timeout:
        return {
            'original_url': original_url,
            'tested_url': test_url,
            'status': 'bad',
            'reason': 'Timeout'
        }
    except requests.exceptions.SSLError:
        return {
            'original_url': original_url,
            'tested_url': test_url,
            'status': 'bad',
            'reason': 'SSL Error'
        }
    except requests.exceptions.ConnectionError:
        return {
            'original_url': original_url,
            'tested_url': test_url,
            'status': 'bad',
            'reason': 'Connection Error'
        }
    except requests.exceptions.RequestException as e:
        return {
            'original_url': original_url,
            'tested_url': test_url,
            'status': 'bad',
            'reason': f'Request Error: {str(e)}'
        }
    except Exception as e:
        return {
            'original_url': original_url,
            'tested_url': test_url,
            'status': 'bad',
            'reason': f'Unexpected error: {str(e)}'
        }

def format_time(seconds):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
    if seconds < 60:
        return f"{seconds:.1f}—Å–µ–∫"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}–º–∏–Ω {secs:.0f}—Å–µ–∫"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}—á {minutes}–º–∏–Ω"

def run_check(stations, output_prefix=""):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É —Å–ø–∏—Å–∫–∞ —Å—Ç–∞–Ω—Ü–∏–π"""
    total_stations = len(stations)
    
    good_urls = []
    bad_urls = []
    
    start_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        future_to_station = {
            executor.submit(check_stream, station['url'], station['url']): station 
            for station in stations
        }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –∏—Ö –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è
        completed = 0
        for future in concurrent.futures.as_completed(future_to_station):
            station = future_to_station[future]
            try:
                result = future.result()
                
                if result['status'] == 'good':
                    good_urls.append({
                        'stationuuid': station['stationuuid'],
                        'original_url': result['original_url'],
                        'tested_url': result['tested_url'],
                        'http_status': result.get('http_status'),
                        'content_type': result.get('content_type'),
                        'content_length': result.get('content_length')
                    })
                    status_icon = '‚úÖ'
                elif result['status'] == 'skipped':
                    bad_urls.append({
                        'stationuuid': station['stationuuid'],
                        'original_url': result['original_url'],
                        'tested_url': result['tested_url'],
                        'reason': result.get('reason')
                    })
                    status_icon = '‚è≠Ô∏è'
                else:
                    bad_urls.append({
                        'stationuuid': station['stationuuid'],
                        'original_url': result['original_url'],
                        'tested_url': result['tested_url'],
                        'reason': result.get('reason'),
                        'http_status': result.get('http_status')
                    })
                    status_icon = '‚ùå'
                
                completed += 1
                
                # –†–∞—Å—á–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏
                elapsed_time = time.time() - start_time
                progress_percent = (completed / total_stations) * 100
                
                # –†–∞—Å—á–µ—Ç –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏
                if completed > 0:
                    avg_time_per_task = elapsed_time / completed
                    remaining_tasks = total_stations - completed
                    estimated_remaining = avg_time_per_task * remaining_tasks
                    eta_str = format_time(estimated_remaining)
                else:
                    eta_str = "—Ä–∞—Å—á–µ—Ç..."
                
                elapsed_str = format_time(elapsed_time)
                
                print(f"{status_icon} [{completed}/{total_stations}] {progress_percent:.1f}% | "
                      f"–ü—Ä–æ—à–ª–æ: {elapsed_str} | –û—Å—Ç–∞–ª–æ—Å—å: {eta_str} | "
                      f"{station['stationuuid'][:8]}... - {result.get('reason', 'OK')}")
                
            except Exception as e:
                completed += 1
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞–Ω—Ü–∏–∏ {station['stationuuid']}: {e}")
                bad_urls.append({
                    'stationuuid': station['stationuuid'],
                    'original_url': station['url'],
                    'tested_url': station['url'],
                    'reason': f'Processing error: {str(e)}'
                })
    
    total_time = time.time() - start_time
    
    return good_urls, bad_urls, total_time

def main():
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–≤–µ—Ä–∫–∞ HTTPS URL —Ä–∞–¥–∏–æ—Å—Ç–∞–Ω—Ü–∏–π')
    parser.add_argument('--retest', action='store_true', help='–†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö URL')
    args = parser.parse_args()
    
    if args.retest:
        print("üîÅ –ó–ê–ü–£–°–ö –í –†–ï–ñ–ò–ú–ï RETEST")
        # –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        try:
            with open('bad_https_urls.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            stations = data.get('bad_urls', [])
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ—É–Ω–∫—Ü–∏–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            stations_for_check = []
            for station in stations:
                stations_for_check.append({
                    'stationuuid': station['stationuuid'],
                    'url': station['original_url']  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                })
            
            print(f"üîÑ –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è–µ–º {len(stations_for_check)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö URL")
            
            good_urls, bad_urls, total_time = run_check(stations_for_check, "retest_")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            try:
                with open('retest_good_https_urls.json', 'w', encoding='utf-8') as f:
                    json.dump({'good_urls': good_urls}, f, indent=2, ensure_ascii=False)
                
                with open('retest_bad_https_urls.json', 'w', encoding='utf-8') as f:
                    json.dump({'bad_urls': bad_urls}, f, indent=2, ensure_ascii=False)
                
                print(f"\n" + "="*60)
                print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–í–¢–û–†–ù–û–ô –ü–†–û–í–ï–†–ö–ò")
                print("="*60)
                print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ URL: {len(good_urls)}")
                print(f"‚ùå –í—Å–µ –µ—â–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ URL: {len(bad_urls)}")
                if len(stations_for_check) > 0:
                    recovery_rate = (len(good_urls) / len(stations_for_check)) * 100
                    print(f"üìà –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {recovery_rate:.1f}%")
                print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {format_time(total_time)}")
                print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ retest_good_https_urls.json –∏ retest_bad_https_urls.json")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            
        except FileNotFoundError:
            print("‚ùå –§–∞–π–ª bad_https_urls.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—ã—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É.")
            return
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
            return
            
    else:
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏
        print("üöÄ –ó–ê–ü–£–°–ö –í –†–ï–ñ–ò–ú–ï –°–¢–ê–ù–î–ê–†–¢–ù–û–ô –ü–†–û–í–ï–†–ö–ò")
        try:
            with open('station_https_checks.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞–Ω—Ü–∏–∏
            stations = data.get('station_https_checks', [])
            print(f"üìª –ù–∞–π–¥–µ–Ω–æ {len(stations)} —Å—Ç–∞–Ω—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            
            good_urls, bad_urls, total_time = run_check(stations)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            try:
                with open('good_https_urls.json', 'w', encoding='utf-8') as f:
                    json.dump({'good_urls': good_urls}, f, indent=2, ensure_ascii=False)
                
                with open('bad_https_urls.json', 'w', encoding='utf-8') as f:
                    json.dump({'bad_urls': bad_urls}, f, indent=2, ensure_ascii=False)
                
                print(f"\n" + "="*60)
                print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò")
                print("="*60)
                print(f"‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ URL: {len(good_urls)}")
                print(f"‚ùå –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ URL: {len(bad_urls)}")
                if len(stations) > 0:
                    print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {(len(good_urls)/len(stations))*100:.1f}%")
                print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {format_time(total_time)}")
                print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ good_https_urls.json –∏ bad_https_urls.json")
                print(f"üí° –î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö URL –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python script.py --retest")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            
        except FileNotFoundError:
            print("‚ùå –§–∞–π–ª station_https_checks.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
            return

if __name__ == "__main__":
    main()